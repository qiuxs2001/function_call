# å¯¼å…¥å¿…è¦çš„åº“
import os  # æ“ä½œç³»ç»Ÿæ¥å£ï¼Œç”¨äºè®¿é—®ç¯å¢ƒå˜é‡
from dotenv import load_dotenv, find_dotenv  # ç”¨äºåŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
from openai import OpenAI  # OpenAI APIå®¢æˆ·ç«¯ï¼Œç”¨äºä¸æ™ºè°±AIè¿›è¡Œäº¤äº’
import json  # JSONæ•°æ®å¤„ç†åº“ï¼Œç”¨äºè§£æå’Œåºåˆ—åŒ–JSONæ•°æ®
import function_tools as ft  # å¯¼å…¥è‡ªå®šä¹‰çš„å·¥å…·å‡½æ•°æ¨¡å—ï¼ŒåŒ…å«ç™¾åº¦æœç´¢ç­‰åŠŸèƒ½
import gradio as gr  # Gradioåº“ï¼Œç”¨äºåˆ›å»ºWebç•Œé¢


def weather_query(user_message, chat_history, platform, model):
    """
    å¤„ç†å¤©æ°”æŸ¥è¯¢çš„å‡½æ•°
    Args:
        user_message: ç”¨æˆ·è¾“å…¥çš„å¤©æ°”æŸ¥è¯¢æ¶ˆæ¯
        chat_history: èŠå¤©å†å²è®°å½•
        platform: é€‰æ‹©çš„å¹³å°ï¼ˆzhipuæˆ–openaiï¼‰
        model: é€‰æ‹©çš„æ¨¡å‹
    Returns:
        tuple: (ç©ºå­—ç¬¦ä¸², æ›´æ–°åçš„èŠå¤©å†å²)
    """
    # æ ¹æ®å¹³å°é€‰æ‹©å®¢æˆ·ç«¯
    if platform == "zhipu":
        current_client = zhipu_client
        # ç¡®ä¿ä½¿ç”¨æ™ºè°±AIæ”¯æŒçš„æ¨¡å‹
        if model not in ["glm-4-flash", "glm-4"]:
            model = "glm-4-flash"
    else:
        current_client = openai_client
        # ç¡®ä¿ä½¿ç”¨OpenAIæ”¯æŒçš„æ¨¡å‹
        if model not in ["gpt-4o-mini", "gpt-3.5-turbo"]:
            model = "gpt-4o-mini"
    
    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤©æ°”æŸ¥è¯¢åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢è¯¦ç»†çš„å¤©æ°”ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ¸©åº¦ã€æ¹¿åº¦ã€ç©ºæ°”è´¨é‡ã€ç©¿è¡£å»ºè®®ã€å¥åº·å»ºè®®å’Œå‡ºè¡Œå»ºè®®ç­‰ã€‚å›ç­”æ—¶å¿…é¡»æ˜ç¡®è¯´æ˜ç”¨æˆ·æ‰€è¦æŸ¥è¯¢çš„å…·ä½“æ—¥æœŸï¼Œä¾‹å¦‚ï¼šâ€æ˜å¤©çš„æ—¥æœŸæ˜¯7æœˆ9æ—¥ï¼Œå¤©æ°”æ˜¯ï¼Œä»Šå¤©çš„æ—¥æœŸæ˜¯7æœˆ8æ—¥â€ï¼Œå¹¶å°†å¤©æ°”ä¿¡æ¯ä»¥æ¸…æ™°ã€ç»“æ„åŒ–çš„æ–¹å¼å‘ˆç°ç»™ç”¨æˆ·ã€‚ä¸éœ€è¦è¦æ±‚ç”¨æˆ·è¡¥å……é—®é¢˜ï¼Œç›´æ¥æŒ‰é—®é¢˜è°ƒç”¨å·¥å…·è·å–æœ€æ–°å¤©æ°”æ•°æ®ã€‚"},
    ]
    
    # æ·»åŠ å¯¹è¯å†å²ï¼ˆä¿ç•™æœ€è¿‘3è½®å¯¹è¯ï¼‰
    for user_msg, ai_msg in chat_history[-3:]:
        messages.extend([
            {"role": "user", "content": user_msg},
            {"role": "assistant", "content": ai_msg}
        ])
    
    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    messages.append({"role": "user", "content": user_message})
    
    # è°ƒç”¨AI
    response = current_client.chat.completions.create(
        model=model,
        messages=messages,
        tools=tools,
        tool_choice="auto"
    )
    
    # å¤„ç†å·¥å…·è°ƒç”¨
    while response.choices[0].message.tool_calls is not None:
        # ç›´æ¥æ·»åŠ assistantæ¶ˆæ¯
        messages.append(response.choices[0].message)
        
        for tool_call in response.choices[0].message.tool_calls:
            args = json.loads(tool_call.function.arguments)
            function_name = tool_call.function.name
            invoke_fun = getattr(ft, function_name)
            result = invoke_fun(**args)
            
            messages.append({
                "role": "tool",
                "content": json.dumps(result, ensure_ascii=False),
                "tool_call_id": tool_call.id
            })
        
        response = current_client.chat.completions.create(
            model=model,
            messages=messages,
            tools=tools
        )
    
    # è·å–AIå›å¤å¹¶æ›´æ–°èŠå¤©å†å²
    ai_reply = response.choices[0].message.content
    chat_history.append((user_message, ai_reply))
    return "", chat_history

def clear_chat():
    """æ¸…ç©ºèŠå¤©å†å²"""
    return [], []

def update_model_choices(platform):
    """æ ¹æ®é€‰æ‹©çš„å¹³å°æ›´æ–°æ¨¡å‹é€‰é¡¹"""
    if platform == "zhipu":
        return gr.Dropdown(choices=["glm-4-flash", "glm-4"], value="glm-4-flash")
    else:
        return gr.Dropdown(choices=["gpt-4o-mini", "gpt-3.5-turbo"], value="gpt-4o-mini")

if __name__ == "__main__":
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv(find_dotenv())
    
    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
    openai_client = OpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        base_url=os.getenv("OPENAI_BASE_URL")
    )
    
    # åˆå§‹åŒ–æ™ºè°±AIå®¢æˆ·ç«¯
    zhipu_client = OpenAI(
        api_key=os.getenv("ZHIPU_API_KEY"),
        base_url=os.getenv("ZHIPU_BASE_URL")
    )
    
    # å®šä¹‰å¯ç”¨å·¥å…·
    tools = [ft.BAIDU_SEARCH, ft.WEATHER_SEARCH]
    
    # åˆ›å»ºGradioç•Œé¢
    with gr.Blocks(title="å¤©æ°”æŸ¥è¯¢åŠ©æ‰‹") as demo:
        gr.Markdown("# æ™ºèƒ½å¤©æ°”æŸ¥è¯¢åŠ©æ‰‹")
        gr.Markdown("è¾“å…¥åŸå¸‚åç§°æˆ–å¤©æ°”ç›¸å…³é—®é¢˜ï¼Œæˆ‘ä¼šå¸®æ‚¨æŸ¥è¯¢æœ€æ–°çš„å¤©æ°”ä¿¡æ¯ï¼")
        
        # åˆ›å»ºå·¦å³å¸ƒå±€
        with gr.Row():
            # å·¦ä¾§èŠå¤©åŒºåŸŸ
            with gr.Column(scale=3):
                # åˆ›å»ºèŠå¤©è®°å½•æ˜¾ç¤ºåŒºåŸŸ
                chatbot = gr.Chatbot(
                    [],
                    height=500,
                    label="å¯¹è¯å†å²",
                    placeholder="æ¬¢è¿ä½¿ç”¨å¤©æ°”æŸ¥è¯¢åŠ©æ‰‹ï¼è¯·è¾“å…¥æ‚¨æƒ³æŸ¥è¯¢çš„åŸå¸‚å¤©æ°”ä¿¡æ¯ã€‚"
                )
                
                # åˆ›å»ºè¾“å…¥æ¡†å’ŒæŒ‰é’®
                with gr.Row():
                    msg = gr.Textbox(
                        placeholder="è¯·è¾“å…¥å¤©æ°”æŸ¥è¯¢ï¼Œå¦‚ï¼šåŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
                        lines=2,
                        label="å¤©æ°”æŸ¥è¯¢",
                        scale=4
                    )
                    send = gr.Button("æŸ¥è¯¢")
                
                # æ·»åŠ æ¸…ç©ºæŒ‰é’®
                clear = gr.Button("æ¸…ç©ºå¯¹è¯")
                
                # æ·»åŠ ç¤ºä¾‹é—®é¢˜
                gr.Examples(
                    examples=[
                        "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
                        "ä¸Šæµ·æ˜å¤©ä¼šä¸‹é›¨å—ï¼Ÿ",
                        "å¹¿å·è¿™å‘¨çš„å¤©æ°”é¢„æŠ¥",
                        "æ·±åœ³ç°åœ¨çš„æ¸©åº¦æ˜¯å¤šå°‘ï¼Ÿ",
                        "æ­å·é€‚åˆç©¿ä»€ä¹ˆè¡£æœï¼Ÿ"
                    ],
                    inputs=msg,
                    label="ç¤ºä¾‹æŸ¥è¯¢"
                )
            
            # å³ä¾§æ¨¡å‹é€‰æ‹©åŒºåŸŸ
            with gr.Column(scale=1):
                gr.Markdown("### æ¨¡å‹è®¾ç½®")
                
                # å¹³å°é€‰æ‹©
                platform_dropdown = gr.Dropdown(
                    choices=["openai", "zhipu"],
                    value="openai",
                    label="é€‰æ‹©å¹³å°",
                    info="é€‰æ‹©AIæœåŠ¡å¹³å°"
                )
                
                # æ¨¡å‹é€‰æ‹©
                model_dropdown = gr.Dropdown(
                    choices=["gpt-4o-mini", "glm-4-flash"],
                    value="gpt-4o-mini",
                    label="é€‰æ‹©æ¨¡å‹",
                    info="é€‰æ‹©å¯¹è¯æ¨¡å‹"
                )
                
                # # æ¨¡å‹ä¿¡æ¯æ˜¾ç¤º
                # gr.Markdown("""
                # ### ğŸ“‹ ä½¿ç”¨è¯´æ˜
                # **OpenAIå¹³å°ï¼š**
                # - gpt-4o-miniï¼šå¿«é€Ÿå“åº”
                # - gpt-3.5-turboï¼šç»å…¸æ¨¡å‹
                
                # **æ™ºè°±AIå¹³å°ï¼š**
                # - glm-4-flashï¼šé«˜é€Ÿå¤„ç†
                # - glm-4ï¼šæ ‡å‡†æ¨¡å‹
                
                # ### ğŸŒŸ åŠŸèƒ½ç‰¹ç‚¹
                # - å®æ—¶å¤©æ°”æŸ¥è¯¢
                # - å¤šåŸå¸‚æ”¯æŒ
                # - è¯¦ç»†å¤©æ°”ä¿¡æ¯
                # - ç©¿è¡£å»ºè®®
                # """)
        
        # ç»‘å®šäº‹ä»¶å¤„ç†å‡½æ•°
        msg.submit(weather_query, [msg, chatbot, platform_dropdown, model_dropdown], [msg, chatbot])
        send.click(weather_query, [msg, chatbot, platform_dropdown, model_dropdown], [msg, chatbot])
        clear.click(clear_chat, outputs=[chatbot, msg])
        
        # å¹³å°é€‰æ‹©å˜åŒ–æ—¶æ›´æ–°æ¨¡å‹é€‰é¡¹
        platform_dropdown.change(update_model_choices, inputs=[platform_dropdown], outputs=[model_dropdown])
    
    # å¯åŠ¨ç•Œé¢
    demo.launch()

        

